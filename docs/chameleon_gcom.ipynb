{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chameleon news recommendation system: Globo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "Create virtual environment:\n",
    "```sh\n",
    "conda env create -f env.yml\n",
    "conda activate chameleon\n",
    "```\n",
    "\n",
    "Download data from [kaggle]() and unzip to `data/gcom` subdirectory; unzip `clicks.zip`.\n",
    "```\n",
    "data/gcom\n",
    "  articles_embeddings.pickle  # Article content embedding results\n",
    "  articles_metadata.csv       # Article metadata\n",
    "  clicks/clicks_hour_*.csv    # Click information for recommendation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Content Representation (ACR) module\n",
    "Function:\n",
    "1. extract features from news articles text and metadata \n",
    "2. learn a distributed representations (embeddings) for each news article context.\n",
    "\n",
    "The inputs for the *ACR* module are \n",
    "1. article metadata attributes (e.g., publisher)\n",
    "2. article textual content, represented as a sequence of word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. ACR Description\n",
    "In this instantiation of the *Textual Features Representation (TFR)* sub-module from ACR module, 1D CNNs over pre-trained Word2Vec embeddings was used to extract features from textual items.  Article's textual features and metadata inputs were combined by using a sequence of Fully Connected (FC) layers to produce *Article Content Embeddings*.\n",
    "\n",
    "For scalability reasons, *Article Content Embeddings* are not directly trained for recommendation task, but for a side task of news metadata classification. For this architecture instantiation of CHAMELEON, they were trained to classify the category (editorial section) of news articles.\n",
    "\n",
    "After training, the *Article Content Embeddings* for news articles (NumPy matrix) are persisted into a Pickle dump file, for further usage by *NAR* module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ACR Preprocessing: Extract features from news articles text and metadata \n",
    "\n",
    "Input\n",
    "* input_articles_csv_path:    path of a CSV containing articles text and metadata\n",
    "* input_word_embeddings_path: path of pre-trained word embeddings: must be in gensim format binary / plain txt\n",
    "\n",
    "Output\n",
    "* output_tf_records_path: exports articles data into TFRecords format\n",
    "* output_word_vocab_embeddings_path: the dictionaries that mapped tokenized words to sequences of int\\\n",
    "* output_label_encoders: metadata the categorical features encoders (**)\n",
    "\n",
    "For Globo.com dataset, we used pre-trained Portuguese word embeddings (skip-gram model (300 dimensions), available [here](http://nilc.icmc.usp.br/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd acr_module && \\\n",
    "DATA_DIR=\"../data/gcom\" && \\\n",
    "python3 -m acr.preprocessing.acr_preprocess_gcom \\\n",
    "\t--input_articles_csv_path ${DATA_DIR}/document_g1/documents_g1.csv \\\n",
    " \t--input_word_embeddings_path ${DATA_DIR}/word2vec/skip_s300.txt \\\n",
    " \t--vocab_most_freq_words 50000 \\\n",
    " \t--output_word_vocab_embeddings_path ${DATA_DIR}/pickles/acr_word_vocab_embeddings.pickle \\\n",
    " \t--output_label_encoders ${DATA_DIR}/pickles/acr_label_encoders.pickle \\\n",
    " \t--output_tf_records_path \"${DATA_DIR}/articles_tfrecords/gcom_articles_tokenized_*.tfrecord.gz\" \\\n",
    " \t--articles_by_tfrecord 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ACR training\n",
    "Learn a distributed representations (embeddings) for each news article context.\n",
    "\n",
    "Input from last step:\n",
    "* train_set_path_regex: path of pre-procesased TFRecords\n",
    "* input_word_vocab_embeddings_path: \n",
    "* input_label_encoders_path: \n",
    "\n",
    "Output: \n",
    "* output_acr_metadata_embeddings_path: the trained *Article Content Embeddings* (NumPy matrix), with the dimensions specified by *acr_embeddings_size*, exported as Pickle dump file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd acr_module && \\\n",
    "DATA_DIR=\"../data/gcom\" && \\\n",
    "JOB_PREFIX=gcom && \\\n",
    "JOB_ID=`whoami`_${JOB_PREFIX}_`date '+%Y_%m_%d_%H%M%S'` && \\\n",
    "MODEL_DIR='/tmp/chameleon/gcom/jobs/'${JOB_ID} && \\\n",
    "echo 'Running training job and outputing to '${MODEL_DIR} && \\\n",
    "python3 -m acr.acr_trainer_gcom \\\n",
    "\t--model_dir ${MODEL_DIR} \\\n",
    "\t--train_set_path_regex \"${DATA_DIR}/articles_tfrecords/gcom_articles_tokenized_*.tfrecord.gz\" \\\n",
    "\t--input_word_vocab_embeddings_path ${DATA_DIR}/pickles/acr_word_vocab_embeddings.pickle \\\n",
    "\t--input_label_encoders_path ${DATA_DIR}/pickles/acr_label_encoders.pickle \\\n",
    "\t--output_acr_metadata_embeddings_path ${DATA_DIR}/pickles/acr_articles_metadata_embeddings.pickle \\\n",
    "\t--batch_size 64 \\\n",
    "\t--truncate_tokens_length 300 \\\n",
    "\t--training_epochs 5 \\\n",
    "\t--learning_rate 3e-4 \\\n",
    "\t--dropout_keep_prob 1.0 \\\n",
    "\t--l2_reg_lambda 7e-4 \\\n",
    "\t--text_feature_extractor \"CNN\" \\\n",
    "\t--cnn_filter_sizes \"3,4,5\" \\\n",
    "\t--cnn_num_filters 128 \\\n",
    "\t--acr_embeddings_size 250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next article recommendation (NAR)\n",
    "The *Next-Article Recommendation (NAR)* module is responsible for providing news articles recommendations for active sessions.\n",
    "\n",
    "The inputs for the *NAR* module are: \n",
    "1. the pre-trained *Article Content Embedding* of the last viewed article; \n",
    "2. the contextual properties of the articles (popularity and recency); \n",
    "3. the user context (e.g. time, location, and device). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. NAR Description\n",
    "\n",
    "Due to the high sparsity of users and their constant interests shift, the CHAMELEON instantiation leverages only session-based contextual information, ignoring possible users’ past sessions.\n",
    "\n",
    "These inputs are combined by Fully Connected layers to produce a *User-Personalized Contextual Article Embedding*, whose representations might differ for the same article, depending on the user context and on the current article context (popularity and recency).\n",
    "\n",
    "The *NAR* module uses a type of Recurrent Neural Network (RNN) – the Long Short-Term Memory (LSTM) – to model the sequence of articles read by users in their sessions, represented by their *User-Personalized Contextual Article Embeddings*. For each article of the sequence, the RNN outputs a *Predicted Next-Article Embedding* – the expected representation of a news content the user would like to read next in the active session.\n",
    "\n",
    "In most deep learning architectures proposed for RS, the neural network outputs a vector whose dimension is the number of available items. Such approach may work for domains were the items number is more stable, like movies and books. Although, in the dynamic scenario of news recommendations, where thousands of news stories are added and removed daily, such approach could require full retrain of the network, as often as new articles are published.\n",
    "\n",
    "For this reason, instead of using a softmax cross-entropy loss, the NAR module is trained to maximize the similarity between the *Predicted Next-Article Embedding* and the *User-Personalized Contextual Article Embedding* corresponding to the next article actually read by the user in his session (positive sample), whilst minimizing its similarity with negative samples (articles not read by the user during the session). With this strategy to deal with item cold-start, a newly published article might be immediately recommended, as soon as its *Article Content Embedding* is trained and added to a repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NAR preprocessing: click pattern into tf format\n",
    "INPUT: \n",
    "* input_clicks_csv_path_regex: users session split by hour\n",
    "\n",
    "OUTPUT:\n",
    "* output_sessions_tfrecords_path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sessions by hour\n",
      "Exporting sessions by hour to TFRecords: ../data/gcom/sessions_tfrecords/sessions_hour_*.tfrecord.gz\n",
      "Exported 0 TFRecord files\n",
      "Preprocessing finalized\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd nar_module && \\\n",
    "DATA_DIR=\"../data/gcom\" && \\\n",
    "python3 -m nar.preprocessing.nar_preprocess_gcom \\\n",
    "--input_clicks_csv_path_regex \"${DATA_DIR}/clicks/clicks_hour_*\" \\\n",
    "--number_hours_to_preprocess 5 \\\n",
    "--output_sessions_tfrecords_path \"${DATA_DIR}/sessions_tfrecords/sessions_hour_*.tfrecord.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. NAR Training and evaluation\n",
    "The *NAR* module is trained and evaluated according to the following *Temporal Offline Evaluation Method*\n",
    "1. Train the NAR module with sessions within the active hour.\n",
    "2. Evaluate the NAR module with sessions within the next hour, for the task of the next-click prediction.\n",
    "\n",
    "INPUT from ACR:\n",
    "- acr_module_articles_metadata_csv_path article metadata path\n",
    "- acr_module_articles_content_embeddings_pickle_path: article content embedding\n",
    "- train_set_path_regex: click info\n",
    "\n",
    "OUTPUT: model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NAR Evaluation\n",
    "\n",
    "The following baseline methods (described in more detail in [2]) are also trained and evaluated in parallel, as benchmarks for CHAMELEON accuracy:\n",
    "- **Co-occurrent (CO)**\n",
    "- **Sequential Rules (SR)**\n",
    "- **Item-kNN**\n",
    "- **Vector Multiplication Session-Based kNN (V-SkNN)**\n",
    "- **Recently Popular (RP)**\n",
    "- **Content-Based (CB)**\n",
    "\n",
    "The choosen evaluation metrics were **Hit-Rate@N** and **MRR@N** for accuracy, **COV** for catalog coverage, **ESI-R** and **ESI-RR** for novelty, and **EILD-R** and **EILD-RR** for diversity, described in [2].\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "It is necessary to specify a subset of files (representing sessions started in the same hour) for training and evaluation (*train_files_from* to *train_files_up_to*). The frequency of evaluation is specified in *training_hours_for_each_eval* (e.g. *training_hours_for_each_eval=5* means that after training on 5 hour's (files) sessions, the next hour (file) is used for evaluation.\n",
    "\n",
    "To reproduce the experiments of [2], where additional features are used as inputs to the NAR module, you must change the following parameters according to the Input Configurations (IC) reported in the paper: *enabled_articles_input_features_groups*, *enabled_clicks_input_features_groups*, *enabled_internal_features*.\n",
    "\n",
    "To reproduce the experiments reported in [2] with the novelty regularization in loss function, change the parameter *novelty_reg_factor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd nar_module && \\\n",
    "DATA_DIR=\"../data/gcom\" && \\\n",
    "JOB_PREFIX=gcom && \\\n",
    "JOB_ID=`whoami`_${JOB_PREFIX}_`date '+%Y_%m_%d_%H%M%S'` && \\\n",
    "MODEL_DIR='/tmp/chameleon/jobs/'${JOB_ID} && \\\n",
    "echo 'Running training job and outputing to '${MODEL_DIR} && \\\n",
    "python3 -m nar.nar_trainer_gcom \\\n",
    "\t--model_dir ${MODEL_DIR} \\\n",
    "\t--acr_module_articles_metadata_csv_path ${DATA_DIR}/articles_metadata.csv \\\n",
    "\t--acr_module_articles_content_embeddings_pickle_path ${DATA_DIR}/articles_embeddings.pickle \\\n",
    "\t--train_set_path_regex \"${DATA_DIR}/sessions_tfrecords/sessions_hour_*.tfrecord.gz\" \\\n",
    "\t--train_files_from 0 \\\n",
    "\t--train_files_up_to 72 \\\n",
    "\t--training_hours_for_each_eval 5 \\\n",
    "\t--save_results_each_n_evals 1 \\\n",
    "\t--batch_size 64 \\\n",
    "\t--truncate_session_length 20 \\\n",
    "\t--learning_rate 3e-5 \\\n",
    "\t--dropout_keep_prob 1.0 \\\n",
    "\t--reg_l2 1e-5 \\\n",
    "\t--softmax_temperature 0.1 \\\n",
    "\t--recent_clicks_buffer_hours 1.0 \\\n",
    "\t--recent_clicks_buffer_max_size 20000 \\\n",
    "\t--recent_clicks_for_normalization 2000 \\\n",
    "\t--eval_metrics_top_n 6 \\\n",
    "\t--CAR_embedding_size 1024 \\\n",
    "\t--rnn_units 255 \\\n",
    "\t--rnn_num_layers 1 \\\n",
    "\t--train_total_negative_samples 30 \\\n",
    "\t--train_negative_samples_from_buffer 3000 \\\n",
    "\t--eval_total_negative_samples 30 \\\n",
    "\t--eval_negative_samples_from_buffer 3000 \\\n",
    "\t--eval_negative_sample_relevance 0.02 \\\n",
    "\t--enabled_articles_input_features_groups \"category\" \\\n",
    "\t--enabled_clicks_input_features_groups \"time,device,location,referrer\" \\\n",
    "\t--enabled_internal_features \"item_clicked_embeddings,recency,novelty,article_content_embeddings\" \\\n",
    "\t--novelty_reg_factor 0.0 \\\n",
    "\t--disable_eval_benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
